{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artificial-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from surrogate_model import Aleatoric_NN, Epistemic_NN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-silence",
   "metadata": {},
   "source": [
    "## Active Learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elder-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_init = 2000\n",
    "n_test = 2000\n",
    "k = [500, 1000, 2000, 4000, 8000, 16000, 32000]\n",
    "m=4\n",
    "iterations = 10\n",
    "active_learning_mses = []\n",
    "baseline_mses = []\n",
    "baseline_ns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = ([-3,3],[-2,2])\n",
    "\n",
    "def six_hump_camel_function(X):\n",
    "    x = X[:,0]\n",
    "    y = X[:,1]\n",
    "\n",
    "    x2 = np.power(x,2)\n",
    "    x4 = np.power(x,4)\n",
    "    y2 = np.power(y,2)\n",
    "\n",
    "    return (4.0 - 2.1 * x2 + (x4 / 3.0)) * x2 + x*y + (-4.0 + 4.0 * y2) * y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "veterinary-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 1200\n",
    "X1 = np.linspace(dom[0][0], dom[0][1], grid)\n",
    "X2 = np.linspace(dom[1][0], dom[1][1], grid)\n",
    "x1, x2 = np.meshgrid(X1, X2)\n",
    "X = np.hstack((x1.reshape(grid*grid,1),x2.reshape(grid*grid,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "australian-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "test_indices = np.random.randint(0, (grid*grid), size = n_test)\n",
    "testset_X = X[test_indices,:]\n",
    "X = np.delete(X, test_indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "light-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "(1438005, 2)\n"
     ]
    }
   ],
   "source": [
    "print(testset_X.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_y = six_hump_camel_function(testset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adult-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_set = X[np.random.randint(0,X.shape[0],n_init),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "substantial-plumbing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "going-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = six_hump_camel_function(init_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "played-magazine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prediction uncertainty: 24.362551271765135\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=0\n",
      "Mean prediction uncertainty: 21.752165954428797\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=1\n",
      "Mean prediction uncertainty: 20.23165186434713\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=2\n",
      "Mean prediction uncertainty: 18.941023048514936\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=3\n",
      "Mean prediction uncertainty: 18.077096483971427\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=4\n",
      "Mean prediction uncertainty: 17.765472253291627\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=5\n",
      "Mean prediction uncertainty: 14.621235226585949\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=6\n",
      "Mean prediction uncertainty: 14.84754636207454\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=7\n",
      "Mean prediction uncertainty: 14.687340388097699\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=8\n",
      "Mean prediction uncertainty: 14.217654548353003\n",
      "trainset size: 2000\n",
      "finished n=500, iteration=9\n",
      "mse: [44.45543047497739]\n",
      "baseline_ns: [5000]\n",
      "Mean prediction uncertainty: 27.566581618392892\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=0\n",
      "Mean prediction uncertainty: 20.975737199133423\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=1\n",
      "Mean prediction uncertainty: 18.07899500860173\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=2\n",
      "Mean prediction uncertainty: 16.288967337304744\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=3\n",
      "Mean prediction uncertainty: 15.63494330676223\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=4\n",
      "Mean prediction uncertainty: 14.273550196796455\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=5\n",
      "Mean prediction uncertainty: 12.771069474275468\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=6\n",
      "Mean prediction uncertainty: 11.505556508072834\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=7\n",
      "Mean prediction uncertainty: 11.726909983088747\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=8\n",
      "Mean prediction uncertainty: 11.067432674176828\n",
      "trainset size: 2000\n",
      "finished n=1000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526]\n",
      "baseline_ns: [5000, 10000]\n",
      "Mean prediction uncertainty: 26.089786296489606\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=0\n",
      "Mean prediction uncertainty: 19.753373134007788\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=1\n",
      "Mean prediction uncertainty: 17.613117081437725\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=2\n",
      "Mean prediction uncertainty: 15.472258009555055\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=3\n",
      "Mean prediction uncertainty: 12.670090391752076\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=4\n",
      "Mean prediction uncertainty: 10.951695725596105\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=5\n",
      "Mean prediction uncertainty: 8.659869316328729\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=6\n",
      "Mean prediction uncertainty: 7.303049015995233\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=7\n",
      "Mean prediction uncertainty: 6.1809695151486315\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=8\n",
      "Mean prediction uncertainty: 5.113120814768198\n",
      "trainset size: 2000\n",
      "finished n=2000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526, 4.306793371512093]\n",
      "baseline_ns: [5000, 10000, 20000]\n",
      "Mean prediction uncertainty: 22.22295198233275\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=0\n",
      "Mean prediction uncertainty: 12.484332417370666\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=1\n",
      "Mean prediction uncertainty: 11.237079999192899\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=2\n",
      "Mean prediction uncertainty: 8.950783172481605\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=3\n",
      "Mean prediction uncertainty: 7.667127345027211\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=4\n",
      "Mean prediction uncertainty: 6.834384796222118\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=5\n",
      "Mean prediction uncertainty: 6.434799346208334\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=6\n",
      "Mean prediction uncertainty: 6.332030555550202\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=7\n",
      "Mean prediction uncertainty: 5.200542263421795\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=8\n",
      "Mean prediction uncertainty: 5.2235970846757525\n",
      "trainset size: 2000\n",
      "finished n=4000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526, 4.306793371512093, 4.493822089247507]\n",
      "baseline_ns: [5000, 10000, 20000, 40000]\n",
      "Mean prediction uncertainty: 31.94829242602883\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=0\n",
      "Mean prediction uncertainty: 9.583709061440258\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=1\n",
      "Mean prediction uncertainty: 5.033092775923565\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=2\n",
      "Mean prediction uncertainty: 3.7184644605163086\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=3\n",
      "Mean prediction uncertainty: 2.78183027825723\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=4\n",
      "Mean prediction uncertainty: 2.802425827642128\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=5\n",
      "Mean prediction uncertainty: 3.368306963323312\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=6\n",
      "Mean prediction uncertainty: 2.043610187717884\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=7\n",
      "Mean prediction uncertainty: 1.982718934202713\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=8\n",
      "Mean prediction uncertainty: 2.024894884060652\n",
      "trainset size: 2000\n",
      "finished n=8000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526, 4.306793371512093, 4.493822089247507, 1.3488441909011584]\n",
      "baseline_ns: [5000, 10000, 20000, 40000, 80000]\n",
      "Mean prediction uncertainty: 25.65693699698143\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=0\n",
      "Mean prediction uncertainty: 7.918248558326963\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=1\n",
      "Mean prediction uncertainty: 6.7312085417346035\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=2\n",
      "Mean prediction uncertainty: 5.1374039037693615\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=3\n",
      "Mean prediction uncertainty: 4.57680683034242\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=4\n",
      "Mean prediction uncertainty: 4.063434120110263\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=5\n",
      "Mean prediction uncertainty: 3.5629246155015775\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=6\n",
      "Mean prediction uncertainty: 4.2236315034485905\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=7\n",
      "Mean prediction uncertainty: 1.8005518041499422\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=8\n",
      "Mean prediction uncertainty: 1.8774006021056702\n",
      "trainset size: 2000\n",
      "finished n=16000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526, 4.306793371512093, 4.493822089247507, 1.3488441909011584, 1.3363680501970872]\n",
      "baseline_ns: [5000, 10000, 20000, 40000, 80000, 160000]\n",
      "Mean prediction uncertainty: 24.712831849731597\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=0\n",
      "Mean prediction uncertainty: 2.5661523747938806\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=1\n",
      "Mean prediction uncertainty: 2.5451720722861015\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=2\n",
      "Mean prediction uncertainty: 2.4003996885782652\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=3\n",
      "Mean prediction uncertainty: 1.4268490219893812\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=4\n",
      "Mean prediction uncertainty: 1.811742480158937\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=5\n",
      "Mean prediction uncertainty: 1.2917165910328072\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=6\n",
      "Mean prediction uncertainty: 1.4321242794096702\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=7\n",
      "Mean prediction uncertainty: 1.7927000463805487\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=8\n",
      "Mean prediction uncertainty: 2.8168558217919855\n",
      "trainset size: 2000\n",
      "finished n=32000, iteration=9\n",
      "mse: [44.45543047497739, 93.41446869396526, 4.306793371512093, 4.493822089247507, 1.3488441909011584, 1.3363680501970872, 1.8125160400178038]\n",
      "baseline_ns: [5000, 10000, 20000, 40000, 80000, 160000, 320000]\n"
     ]
    }
   ],
   "source": [
    "for j in k:\n",
    "    total_n = 0\n",
    "    nn = Epistemic_NN()\n",
    "    start_set = copy.deepcopy(init_set)\n",
    "    y_new = copy.deepcopy(y)\n",
    "    nn.create_model(start_set)\n",
    "    nn.fit(start_set, y_new, epochs = 25)\n",
    "    for i in range(iterations):\n",
    "        new_set = X[np.random.randint(0,X.shape[0],m*j),:]\n",
    "        evaluation_m, evaluation_s = nn.predict(new_set)\n",
    "        #print(evaluation_s)\n",
    "        highest_error_indices = np.argpartition(evaluation_s, -j)[-j:]\n",
    "        y_new_ = six_hump_camel_function(new_set[highest_error_indices,:])\n",
    "        print(f\"Mean prediction uncertainty: {np.mean(evaluation_s[highest_error_indices])}\")\n",
    "        #start_set = np.concatenate((start_set,  new_set[highest_error_indices]), axis = 0)\n",
    "        print(f\"trainset size: {start_set.shape[0]}\")\n",
    "        #y_new = np.concatenate((y_new, y_new_), axis=0)\n",
    "        nn.updateModel(new_set[highest_error_indices,:], y_new_, epochs = 20, verbose=0)\n",
    "        total_n+=j\n",
    "        print(f\"finished n={j}, iteration={i}\")\n",
    "    nn.model.save(f\"AL_{j}.h5\")\n",
    "        \n",
    "    test_m, test_s = nn.predict(testset_X)\n",
    "    active_learning_mses.append(mean_squared_error(testset_y, test_m))\n",
    "    print(f\"mse: {active_learning_mses}\")\n",
    "    baseline_ns.append(total_n)\n",
    "    print(f\"baseline_ns: {baseline_ns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-accordance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-parts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERP_DT_SI",
   "language": "python",
   "name": "erp_dt_si"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
